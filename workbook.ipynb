{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b64097d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import choice\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from symusic import Score\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0467248",
   "metadata": {},
   "source": [
    "@inproceedings{pop909-ismir2020,\n",
    "    author = {Ziyu Wang* and Ke Chen* and Junyan Jiang and Yiyi Zhang and Maoran Xu and Shuqi Dai and Guxian Bin and Gus Xia},\n",
    "    title = {POP909: A Pop-song Dataset for Music Arrangement Generation},\n",
    "    booktitle = {Proceedings of 21st International Conference on Music Information Retrieval, {ISMIR}},\n",
    "    year = {2020}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ac9511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = glob.glob(\"POP909/**/*.mid\", recursive=True)\n",
    "\n",
    "tokenizer = REMI()  # using defaults parameters (constants.py)\n",
    "train_dataset = DatasetMIDI(\n",
    "    files_paths=FILE_PATH,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "test_dataset = DatasetMIDI(\n",
    "    files_paths=FILE_PATH,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id)\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6701725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(MusicRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch_size, seq_length)\n",
    "        x = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        out, hidden = self.rnn(x, hidden)  # out: (batch_size, seq_length, hidden_dim)\n",
    "        out = self.fc(out)  # (batch_size, seq_length, vocab_size)\n",
    "        return out, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523bc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, vocab_size, num_epochs=20, lr=0.001, device='mps'):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --------- Training ---------\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            batch = batch['input_ids'].to(device)  # (batch_size, seq_length)\n",
    "\n",
    "            inputs = batch[:, :-1]\n",
    "            targets = batch[:, 1:]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            outputs = outputs.reshape(-1, vocab_size)\n",
    "            targets = targets.reshape(-1)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "        # --------- Validation ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch['input_ids'].to(device)\n",
    "\n",
    "                inputs = batch[:, :-1]\n",
    "                targets = batch[:, 1:]\n",
    "\n",
    "                outputs, _ = model(inputs)\n",
    "                outputs = outputs.reshape(-1, vocab_size)\n",
    "                targets = targets.reshape(-1)\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    embedding_dim = 256\n",
    "    hidden_dim = 512\n",
    "    num_layers = 2\n",
    "\n",
    "    model = MusicRNN(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "    train(model, train_loader, test_loader, vocab_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
